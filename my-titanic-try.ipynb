{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "scrolled": true
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom matplotlib import colors\nfrom matplotlib.ticker import PercentFormatter\nimport seaborn as sns\n\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "31f9fa0ad37a4490411bc882d3ab3cb6f71031a4"
      },
      "cell_type": "markdown",
      "source": "# Import and Preparation"
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "df_train = pd.read_csv('../input/train.csv', index_col='PassengerId')\ndf_test = pd.read_csv('../input/test.csv', index_col='PassengerId')\ndf_gender_sub = pd.read_csv(\"../input/gender_submission.csv\", index_col='PassengerId')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "93f454dfae6bfa406b1525dc1e94630919fba987",
        "scrolled": true
      },
      "cell_type": "code",
      "source": "# Storing the target separately\nSurvived = df_train.loc[:,'Survived']\ndf_train = df_train.drop(['Survived'], axis=1).copy()\n\n# Saving index for train test split \ntrain_index = df_train.index\ntest_index = df_test.index\n\n# Concate the two datasets\ndf_all = pd.concat([df_train, df_test])\n\n# dont needed anymore\n##del df_train\n##del df_test\n\n# Create new feature Family true/false\ndf_all.loc[:,'Family'] = ((df_all['SibSp'] > 0) | (df_all['Parch'] > 0)).replace(True, 1, inplace=False)\ndf_all.loc[:,'Family'] = df_all.loc[:,'Family'].astype(int)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d70d764b2c7cf7eab5f3855b2ca45a4608e20e15"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7820ee766cb9f31130010637035df89dfa695455"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "e51e3d019489965faf9fe7a6eb0b623ee25bc642"
      },
      "cell_type": "markdown",
      "source": "# Missing Values"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "33f50d0c8daccc602d4aa5222607f9fb2ff37e89"
      },
      "cell_type": "code",
      "source": "# Function for nullanalysis\ndef nullAnalysis(df):\n    tab_info=pd.DataFrame(df.dtypes).T.rename(index={0:'column type'})\n\n    tab_info=tab_info.append(pd.DataFrame(df.isnull().sum()).T.rename(index={0:'null values (nb)'}))\n    tab_info=tab_info.append(pd.DataFrame(df.isnull().sum()/df.shape[0]*100)\n                         .T.rename(index={0:'null values (%)'}))\n    return tab_info",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f61fd8d0c8ceedf3b11d071e9c8e82ad9c227349"
      },
      "cell_type": "code",
      "source": "# Show the null values\nnullAnalysis(df_all)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "8e732d45cfadbef6b465ab5adcf2f0ddc6a5d6dc"
      },
      "cell_type": "markdown",
      "source": "## Age"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "26f1af74618dcee236d9d03db84cf971f06f1053"
      },
      "cell_type": "code",
      "source": "# First 10 datarows where age is null\ndf_all[df_all.loc[:,'Age'].isnull()].head(10)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1d73825103f4a469b6b4af373f7a974bc414350b",
        "scrolled": true
      },
      "cell_type": "code",
      "source": "# Average age overall\nprint(\"Average age of a passengers: \", round(df_all.loc[:,'Age'].agg('mean'),0))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b9abde06c946280939cd677a07c83082782954da"
      },
      "cell_type": "code",
      "source": "# Average age per class\ndf_all.groupby('Pclass')['Age'].agg('mean')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "ee17d17a68c835ab1a8168975cfd159a8cf435e6"
      },
      "cell_type": "markdown",
      "source": "We will use the average age of the corresponding class to fill the missing passenger ages. This would be the best fit for that problem."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "862144b2cf973b660791ddf05f98e8e493cd796c"
      },
      "cell_type": "code",
      "source": "# Setting the average age of each class for the missing values inside the corresponding class\ndf_all.loc[(df_all['Age'].isnull()) & (df_all['Pclass'] == 1), ['Age']] = round(df_all.groupby('Pclass')['Age'].agg('mean')[1],0)\ndf_all.loc[(df_all['Age'].isnull()) & (df_all['Pclass'] == 2), ['Age']] = round(df_all.groupby('Pclass')['Age'].agg('mean')[2],0)\ndf_all.loc[(df_all['Age'].isnull()) & (df_all['Pclass'] == 3), ['Age']] = round(df_all.groupby('Pclass')['Age'].agg('mean')[3],0)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "1e9e6fd8702ac0c818ba367856016783e8112f9c"
      },
      "cell_type": "markdown",
      "source": "## Fare\n"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "bb3630fad919ec1b8778472b5507547cb4f99434"
      },
      "cell_type": "code",
      "source": "df_all[df_all['Fare'].isnull()]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "72f2e3727caa724d0afa43c73aad7666871c5537"
      },
      "cell_type": "markdown",
      "source": "One passenger has not payed his Ticket, or is even not recorded. To fill the gab I will use the mean ticket price for his third class ticket: 13.30 "
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "_uuid": "1f72b972dddf129302de5b22bd1106d0ed223d99"
      },
      "cell_type": "code",
      "source": "df_all.groupby('Pclass', as_index=False)['Fare'].agg('mean')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "887e0f5121e468493409a7a6e143b63d2e199081"
      },
      "cell_type": "code",
      "source": "# Setting Fare to mean fare of pclass\ndf_all.loc[1044,['Fare']] = 13.30",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "9ca201dfc10bc37ea0e3026a7c7244bb14082a74"
      },
      "cell_type": "markdown",
      "source": "## Cabin"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "93ee72954e359ad0f4f0b93bc52b2c2f0ed743f5",
        "scrolled": true
      },
      "cell_type": "code",
      "source": "# Show all Cabins with NaN data\ndf_all.loc[(df_all['Cabin'].isnull())].count()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "d226a5fad1f989261ec4dd99aa64412c32ff4917"
      },
      "cell_type": "markdown",
      "source": "The *Cabin* situation looks pretty bad. From the 1309 data points are only roundabout 300 filled with *Cabin* information, the other 1000 data points are empty. I assumed with the cabin information one could rather conclude on a passengers survival or not. I don't want to use the fillna() - method with this sparely filled feature, that would not make any sense and will probably affect my results badly.  Lets look into the *Cabin* distribution compared the the *Pclass*"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "46dcda86e2eff648075c0a41a742e45a21308509"
      },
      "cell_type": "code",
      "source": "# Group by Pclasses\ndf_all.groupby('Pclass').agg('count')[['Name','Cabin']]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "7e5e36327dd9f97729d2095520505281d2535c39"
      },
      "cell_type": "markdown",
      "source": "The round about 300 filled examples for the *Cabin* information are fairly one-sided distributed to the first class (*Pclass*). The *Name* shows the total distribution for the cabin class, so 256 passengers of 323 first class passengers have a *Cabin* information available. Only 39 *Cabin* values are filled in the second and third class (*Pclass*), they are divided up with 23 in second and 16 in third class. In comparision to the amount of passengers makes it not better, there are 709 passengers in the third class and 277 in second class. First class has 323 passengers in it's area. The completeness of the data in relation to the number of passengers per class is as follows:"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c15d6f904cd5b10d38058efe1d14380e903d0545",
        "scrolled": true
      },
      "cell_type": "code",
      "source": "(df_all.groupby('Pclass').agg('count')['Cabin'] / df_all.groupby('Pclass').agg('count')['Name'])*100",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "f270ab1fbebd8ec6cb0069c50c43d270bfacfb0b"
      },
      "cell_type": "markdown",
      "source": "It clearly shows that the second and third class are sparsely filled with in comparision to their passengers count. The first class in comparision looks with nearly 80% pretty good. One could consider applying the **fillNa** only to the first class and using a different method for the second and third class.\n\nWhile analysing the *Cabin* feature I realize there are sometimes multiple values inside the *Cabin* feature. The following table shows you the multiple *Cabin* values:"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "abcfb09b85c1fd263872db699c9ac9f0d5647451"
      },
      "cell_type": "code",
      "source": "df_all[df_all['Cabin'].str.contains(' ', regex=False) == True].sort_values(by='Cabin')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "5e785a04722cca85d5ef67c77d24897760bc8ac9"
      },
      "cell_type": "markdown",
      "source": "There is a way to split the string values easily but the information gain from the 41 examples in comparision to the round about 1000 missing values is pretty low:"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "fd53c7ddecf19da3b3e10230f452212aa96daab1"
      },
      "cell_type": "code",
      "source": "# Creating a data frame for the Cabin values to split multiple values into seperate columns\ndf_cabin_expand = df_all.loc[:,'Cabin'].str.split(' ', expand=True)\n\n# Group all doubled values by the first value\ndf_cabin_expand[df_cabin_expand.loc[:,1].isnull() == False].groupby([0]).count()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1936fe7e7a3f86a27922221fb259c398a1b8254f"
      },
      "cell_type": "markdown",
      "source": "The *Cabin* feature will be dropped at least. It there is no way of restoring the informaiton from this column, the duplicate values are not enough to restore all missing values and the other features to not supply enough information to restore this based of them."
    },
    {
      "metadata": {
        "_uuid": "5e08e4c1079d9921276ffbada2c8989854b936e5"
      },
      "cell_type": "markdown",
      "source": "## Salutation\nWith analyzing the *Cabin* feature I realized there exists different salutations in the passengers *Name* feature. The string split funciton will be usefull here, mentioned in the *Cabin* feature analysis. The values differ among others as follows:\n"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f9e61a3a00cd6122f33e217998d1e947cf702f4b",
        "scrolled": false
      },
      "cell_type": "code",
      "source": "# Split Name feature strings into several columns\ndf_name_salutation = df_all.loc[:,'Name'].str.split(' ', expand=True)\ndf_name_salutation.groupby(1).count()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "880156e1bd90160d2db8507f39497d41e67b9b13"
      },
      "cell_type": "markdown",
      "source": "Here is still something to clean but you can clearly see, that the most values in the split column \"1\" refers to the passengers salutation. Moreover I recognized that the salutations strings always ends with a dot.:\n\n- Capt. - Captain\n- Col. - Colonel\n- Don. - Don\n- Dr. - Doctor\n- Major.\n- Master. - \"a way of addressing politely a boy ... too young to be called 'Mister'.\" - *Leslie Dunkling*  \n- Miss. \n- Mlle. - Mademoiselle\n- Mme. - Madame\n- Mr.\n- Mrs.\n- Ms.\n- Countess.\n- ...\n\nNext I will retriev the single salutations from column 1 and 2 based on the string value \".\" (dot) and concatenate the two columns to one salutation column and append these to the main dataframe. "
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f604840d656a83df4c5ba5b04d0e1dcb4086b589",
        "scrolled": false
      },
      "cell_type": "code",
      "source": "# Extract Salutation from every column based on the '.'\ndf_newsal_1 = df_name_salutation[df_name_salutation[1].str.contains('.', regex=False)][1]\ndf_newsal_2 = df_name_salutation[df_name_salutation[2].str.contains('.', regex=False)][2]\ndf_newsal_3 = df_name_salutation[(df_name_salutation[3].isnull() == False) & (df_name_salutation[3].str.contains('.', regex=False))][3]\n\n# Rename column for append \ndf_newsal_2 = df_newsal_2.rename(1)\ndf_newsal_3 =  df_newsal_3.rename(1)\n\n# Append both salutations results to one column and rename them\ndf_newsal = df_newsal_1.append([df_newsal_2, df_newsal_3])\ndf_newsal = df_newsal.rename('Salutation')\n\n# Concatenate them to the main dataframe\ndf_all = pd.concat([df_all,df_newsal],axis=1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "736561fa345bc8b5f8b597d816cb275a83761e0f"
      },
      "cell_type": "markdown",
      "source": "The following list shows all the salutation distribution. Nothing is leftover right now:"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b254d9af134a0b8f2576f64465f9f68bb91e8ee9"
      },
      "cell_type": "code",
      "source": "df_all.groupby('Salutation').count()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "40462197d99b08e05a1c5ee97df4f176506324b7"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "55020ebdd9bb21e61cdfac2e3f27dca14735b117"
      },
      "cell_type": "markdown",
      "source": "# Feature Distribution"
    },
    {
      "metadata": {
        "_uuid": "50e3ec0f63afa947d42fbcb97c6e32804a75ac31"
      },
      "cell_type": "markdown",
      "source": "## Gender Distribution"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "92f3a1c3d02355f655c7e452fb22f31e6ea52748",
        "_kg_hide-input": true
      },
      "cell_type": "code",
      "source": "# Gender distribution\ndf_all.groupby(['Parch']).agg('count')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "72219f07d4928ff88b9205d044b34c9d16d40eac"
      },
      "cell_type": "markdown",
      "source": "The feature **Cabin** seems to have some missing values."
    },
    {
      "metadata": {
        "_uuid": "9feacfd5ba2bc12dae3da0a52a31f5dd70af9e44"
      },
      "cell_type": "markdown",
      "source": "## Gender Distribution by Ticket Class\nFollowing will show the gender distribution by ticket class."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "68baf6b3e3f5a26e9152a195334b58da9feca64e",
        "_kg_hide-input": true
      },
      "cell_type": "code",
      "source": "# Visualizing pie chart\n\nfig, ax = plt.subplots(figsize=(10,7))\n\n# Size and explsion\nsize_out = 3\nsize_in = 1\nexplode_out = (0.2,0.2)\nexplode_in = (0.3,0.3,0.3,0.3,0.3,0.3)\n\ncmap = plt.get_cmap('tab20c')\n\nouter_colors = cmap(np.array([8,0]))\ninner_colors = cmap(np.array([11,10,9,3,2,1]))\n\npatches1, texts1, autotexts1 = ax.pie(df_all.groupby(['Sex']).count().Name, radius=3, colors=outer_colors,\n       labels=df_all.groupby(['Sex']).count().Name.index,autopct='%1.1f%%',pctdistance=0.85,\n       wedgeprops=dict(width=size_out, edgecolor='black'),\n       explode = explode_out)\n\npatches2, texts2, autotexts2 = ax.pie(df_all.groupby(['Sex','Pclass']).count().Name, radius=2, colors=inner_colors,\n       labels=[1,2,3,1,2,3],autopct='%1.1f%%', labeldistance=0.88,pctdistance=0.55,\n       wedgeprops=dict(width=size_in, edgecolor='black'),\n      explode = explode_in)\n\n# Centre Cirle\ncentre_circle = plt.Circle((0,0),1.5,color='black', fc='white',linewidth=0)\nfig = plt.gcf()\nfig.gca().add_artist(centre_circle)\n\n#plt.rcParams['font.size'] = 10.0\n#plt.rc_context\n\n\n# Define the labels on the outer plot\nfor t in texts1:\n    t.set_size('large')\nfor t in autotexts1:\n    t.set_size('large')\n#autotexts1[0].set_color('y')\n\n\n# Define the labels on the inner plot\nfor t in texts2:\n    t.set_size('large')\nfor t in autotexts2:\n    t.set_size('large')\n#autotexts2[0].set_color('d')\n\n\n# Setting legend\nax.legend(loc='lower right', bbox_to_anchor=(0.7, 0., 0.5, 0.5), shadow=1,title='Legend',\n          handletextpad=1, labelspacing=0.5 , fontsize='12', labels=['female','male','1. class','2. class', '3. class','1. class','2. class', '3. class'])\n\n\nax.set(aspect=\"equal\", title='Gender Distribution')\nplt.axis('equal')\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4adda7f3e4de7c9cededc244cfb403fff49532b6"
      },
      "cell_type": "markdown",
      "source": "Here you can see the diffrent gender distributions to the ticket classes 1 to 3."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "dca910364c16bcf3daf307ba31859b22fcfdbc50"
      },
      "cell_type": "markdown",
      "source": "## Age Distribution by Ticket Class\nNow the age distribution per ticket class will be visualized to get a better overview about the ages in each ticket class."
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "_uuid": "36bd58c103f360c41c3806bfb0b763f78683d430"
      },
      "cell_type": "code",
      "source": "# Sclicing the three classes\ndf_firstclass_ages = df_all[df_all.loc[:,'Pclass'] == 1]['Age'].copy()\ndf_secondclass_ages = df_all[df_all.loc[:,'Pclass'] == 2]['Age'].copy()\ndf_thirdclass_ages = df_all[df_all.loc[:,'Pclass'] == 3]['Age'].copy()\n\n# Combining all classes in an array\ndf_all_class_ages =[df_firstclass_ages.values,\n                    df_secondclass_ages.values,\n                    df_thirdclass_ages.values]\n\n# Font dictionary\nfont = {'color':  'black',\n        'weight': 'normal',\n        'size': 18,\n}\n\n# Building the figure and the axes for the plot\nfig, axes = plt.subplots(nrows=1, ncols=1, figsize=(12, 6) )\n\n# plot violin plot\nparts = axes.violinplot(df_all_class_ages\n                   ,showmeans=False,\n                    showmedians=True)\naxes.set_title('Age Distribution per Class', fontdict=font, fontsize=25)\n\n# Styling every violin in the graph\nfor pc in parts['bodies']:\n    pc.set_facecolor('#FF8C00')\n    pc.set_edgecolor('#000000')\n    pc.set_linewidth(2)\n    pc.set_alpha(0.7)\n\n\n# adding horizontal grid lines\naxes.yaxis.grid(True)\naxes.set_xticks([y + 1 for y in range(len(df_all_class_ages))])\naxes.set_xlabel('Class',fontdict=font, labelpad=20, size=20)\naxes.set_ylabel('Age', fontdict=font,labelpad=20, size=20)\n\n\naxes.vlines(1, df_firstclass_ages.describe()['25%'], df_firstclass_ages.describe()['75%'], color=['#000000'], linestyle='-', lw=5)\naxes.vlines(2, df_secondclass_ages.describe()['25%'], df_secondclass_ages.describe()['75%'], color=['#000000'], linestyle='-', lw=5)\naxes.vlines(3, df_thirdclass_ages.describe()['25%'], df_thirdclass_ages.describe()['75%'], color=['#000000'], linestyle='-', lw=5)\n#axes.vlines(2, whiskersMin, whiskersMax, color='k', linestyle='-', lw=1)\n\n# add x-tick labels\nplt.setp(axes, xticks=[y + 1 for y in range(len(df_all_class_ages))],\n         xticklabels=['First', 'Second','Third'])\n\n\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true,
        "_uuid": "4ac00273d417b85bf0c16858991fd3ed51e02ca7"
      },
      "cell_type": "markdown",
      "source": "The first class has a wide range of passengers with a mean age of nearly 40. This looks different in the second class. The passengers have at least the same range of ages but the mean age here is more in the area of 30 years. The same is with third class but here is the age range not so high as with the other classes. Its even much smaller outside the mean age of 25. The most passengers in the third class are around 25 years old. "
    },
    {
      "metadata": {
        "_uuid": "c2544de3cc946022d79d9e7f05339d2887cf7867"
      },
      "cell_type": "markdown",
      "source": "## Salutation Distribution\n"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5c453b4a8d98086598c083c1a01b8928f5f1d04d"
      },
      "cell_type": "code",
      "source": "df_all['Salutation']",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "f8c7c70ee6278e3ead51fd9673c2e8662197950b"
      },
      "cell_type": "markdown",
      "source": "# Survivor Distribution\nIn this chapter we will focus on the survivor distribution. In comparision to the **Feature Distribution** we will only focus on the training dataset because we only  have falid survival information in this dataset. The training dataset only includes 891 and not 1309 as in the **Feature Distribution**, therefore the distribution will look here slightly different.\n"
    },
    {
      "metadata": {
        "_uuid": "548a3354ab7f5fee3c9af73752c94885577d29e1"
      },
      "cell_type": "markdown",
      "source": "## Male and Female Survivor\nAccording to the distribution of 64.5% man and 35.6% women, I will now show the distribution of survivors broken down by gender. This distribution only shows the survival data for 891 passengers (from training data) and not for all ship passengers.  \n"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "53bcf0490484879594121af831707e1a2504a871",
        "_kg_hide-input": true
      },
      "cell_type": "code",
      "source": "# The dataset with survived information\ndf_survivalinfo = pd.concat([df_all.loc[train_index,:], Survived], axis=1)\n\n# Survival distribution per Sex\ngp_survived_gender = df_survivalinfo.groupby(['Survived','Sex'])['Name'].count()[1]\n\n# Gender Survival\ngp_gender_survived = df_survivalinfo.groupby(['Sex','Survived']).count()['Name']\n\n# Survival distribution Y/N \ngp_survived_yn = df_survivalinfo.groupby(['Survived']).agg('count')['Name']\n\n# Survival total female / male \ngp_survival_total = df_survivalinfo.groupby(['Sex','Survived']).count().xs('Name', axis=1)\n\n\n# Labels and size based on survival group by (df_survivalinfo)\n#labels_suvinf = ['not suvived','survived']\nsizes_suvinf = [gp_survived_yn[y] for y in range(len(gp_survived_yn))]\nexplode_suvinf = (0, 0.1)  # only \"explode\" the 2nd slice (i.e. 'Hogs')\n\n# Labels and size based on gender group by (gp_sex_survived)\nlabels_sexinf = [gp_survived_gender.index[y] for y in range(len(gp_survived_gender.index))]\nsizes_sexinf = [gp_survived_gender[y] for y in range(len(gp_survived_gender))]\nexplode_sexinf = (0, 0.1)  # only \"explode\" the 2nd slice (i.e. 'Hogs')\n\n# Labels and size MALE Survivor Distribution\nlabels_maleinf = [gp_gender_survived['male'].index[y] for y in range(len(gp_gender_survived['male'].index))]\nsizes_maleinf = [gp_gender_survived['male'][y] for y in range(len(gp_gender_survived['male']))]\nexplode_maleinf = (0, 0.1)  # only \"explode\" the 2nd slice (i.e. 'Hogs')\n\n# Labels and size FEMALE Survivor Distribution\nlabels_femaleinf = [gp_gender_survived['female'].index[y] for y in range(len(gp_gender_survived['female'].index))]\nsizes_femaleinf = [gp_gender_survived['female'][y] for y in range(len(gp_gender_survived['female']))]\nexplode_femaleinf = (0, 0.1)  # only \"explode\" the 2nd slice (i.e. 'Hogs')\n\n# Labels and size total survival data\nlabels_totalsuvinf = [gp_survival_total.index[y] for y in range(len(gp_gender_survived.index))]\nsizes_totalsuvinf = [gp_survival_total[y] for y in range(len(gp_survival_total))]\nexplode_totalsuvinf = (0.3, 0.0, 0.1, 0.0)  # not survived (fm), survived(fm), not survived(m), survived(m)\n\n\n# Font dictionary\nfont = {'color':  'black',\n        'weight': 'normal',\n        #'size': 15,\n        'fontsize':15\n}\n\n# Color maps for the pies\ncmap = plt.get_cmap('tab20c')\nsurvivedcolor = cmap(np.array([5,1]))\nsurvivorallcolor = cmap(np.array([9,10,0,1]))\n\n# Figure and axes of the plot / 4 * 2 plots \ngridsize = (4,2)\nfig1 = plt.figure(figsize=(14,10))\nax1 = plt.subplot2grid(gridsize, (0,0))\nax2 = plt.subplot2grid(gridsize, (0,1))\nax3 = plt.subplot2grid(gridsize, (1,0))\nax4 = plt.subplot2grid(gridsize, (1,1))\nax5 = plt.subplot2grid(gridsize, (2,0), colspan= 2, rowspan= 2)\n\n## fig1 configs\nfig1.suptitle('Distributions of 891 Passengers (Trainingset)', fontsize=25)\n\n## ax1 \n# Define first pie for survival true falls\nax1.pie(sizes_suvinf, \n        explode=explode_suvinf,\n        #labels=labels_suvinf,\n        autopct='%1.1f%%',\n        shadow=True, startangle=90,\n        colors=survivedcolor,\n        labeldistance=1.15,\n        pctdistance=0.55\n       )\nax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n#ax1.fontdict=font\nax1.legend(loc='upper left',fontsize='12',labels=('not survived', 'survived'))\nax1.set_title('Survivor Distribution', fontdict=font, fontsize=20)\n\n## ax2 \n# Define second pie for sex to survival\nax2.pie(sizes_sexinf, \n        explode=explode_sexinf,\n        #labels=labels_sexinf,\n        autopct='%1.1f%%',\n        shadow=True, startangle=90,\n        colors=outer_colors,\n        labeldistance=1.15,\n        pctdistance=0.55)\nax2.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n#ax2.fontdict=font\nax2.legend(loc='upper right', fontsize='12', labels=labels_sexinf )\nax2.set_title('Gender Survivors', fontdict=font, fontsize=20)\n\nax3.pie(sizes_maleinf, \n        explode=explode_maleinf,\n        #labels=labels_sexinf,\n        autopct='%1.1f%%',\n        shadow=True, startangle=90,\n        colors=survivedcolor,\n        labeldistance=1.15,\n        pctdistance=0.55)\n#ax3.fontdict=font\nax3.legend(loc='lower left', fontsize='12', labels=['not survived','survived'] )\nax3.set_title('Male Survivors', fontdict=font, fontsize=20)\nax3.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n\n\nax4.pie(sizes_femaleinf, \n        explode=explode_femaleinf,\n        #labels=labels_sexinf,\n        autopct='%1.1f%%',\n        shadow=True, startangle=90,\n        colors=survivedcolor,\n        labeldistance=1.15,\n        pctdistance=0.55)\n#ax4.fontdict=font\nax4.legend(loc='lower right', fontsize='12', labels=['not survived','survived'] )\nax4.set_title('Female Survivors', fontdict=font, fontsize=20)\nax4.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n\n\nax5.pie(sizes_totalsuvinf, \n        explode=explode_totalsuvinf,\n        #labels=labels_totalsuvinf,\n        autopct='%1.1f%%',\n        shadow=True, startangle=90,\n        colors=survivorallcolor,\n        labeldistance=1.15,\n        pctdistance=0.55)\nax5.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n#ax4.fontdict=font\nax5.legend(loc='lower right', fontsize='12', labels=['female not survived','female survived','male not survived','male survived'] )\nax5.set_title('Overall Survivors', fontdict=font, fontsize=20)\nax5.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "be68f05bc883b9d175a672bb342233ccd9cea03a"
      },
      "cell_type": "markdown",
      "source": "In total of the 891 passenger informations are 62% that did not made it out of the tragedy and died in the open water.  These survivors are divided into 68.1% women and 31.9% man. It is clearly visible that a lot of female passengers have been rescued. If we look closer into the male passengers data (third pie chart: \"Male Survivors), 81% of the male passengers did not survive. In conctract, 74% female passengers survived. That's according to the gentleman's behavior of that time. This situation is best described by a quote of sir ....\n\n\n68% man and 32% women. So at least a lot of male passengers on board. \n\n"
    },
    {
      "metadata": {
        "_uuid": "98c66dbd910a1780a31dcd1341f88dc98542a8ea"
      },
      "cell_type": "markdown",
      "source": "_______________________\nhttps://seaborn.pydata.org/examples/many_facets.html\n_______________________"
    },
    {
      "metadata": {
        "_uuid": "b0aa0be10edd53e3ba15be9fe246f8cbe65e8c31"
      },
      "cell_type": "markdown",
      "source": "\n## Distribution of  Ticket Class to Survival\n"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5ac4f79f3b7b5a9064716ede0249a180310a8c25",
        "_kg_hide-input": true
      },
      "cell_type": "code",
      "source": "# Grouped by Survived and Pclass\ngp_survpclass = df_survivalinfo.groupby(['Survived','Pclass'])['Name'].count()\n\ngridsize = (1,2)\nfig1 = plt.figure(figsize=(12,8))\nax1 = plt.subplot2grid(gridsize, (0,0), colspan=2, rowspan=1)\n\n# Bar chart design\nbar_width = 0.35\ncmap = plt.get_cmap('tab20b')\n\nsurvbarcol = cmap(np.array([7]))\nnsurvbarcol = cmap(np.array([12]))\n\nbarindex = gp_survpclass[0].index   # Group by index of bar plot data\nxtickslables = [barindex[y] for y in range(len(gp_survpclass[0].index))]\n\n\n\nax1.bar(barindex\n        ,gp_survpclass[0].values\n        ,bar_width\n        ,color=nsurvbarcol\n        )\n\nax1.bar(barindex + bar_width\n        ,gp_survpclass[1].values\n        ,bar_width\n        ,color=survbarcol)\n\nax1.set_xlabel('Ticket Class')\nax1.set_ylabel('Passenger Count')\nax1.set_title('Suvivors per Ticket Class')\nax1.set_xticks(barindex + bar_width / 2)\nax1.set_xticklabels(xtickslables)\nax1.legend(labels=('not survived','survived'))\n\nfig.tight_layout()\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ad25094549300d933eb11777e553b250386439d0"
      },
      "cell_type": "code",
      "source": "ptbl = pd.DataFrame.pivot_table(df_survivalinfo, values=['Fare', 'Survived'], index=['Pclass'],\n                     aggfunc={'Survived': ['sum'], 'Fare': [min,max,np.mean]})\n\nptbl\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "dbd5732cd2aeaabde22bc888e64443bfc1f0ad6b"
      },
      "cell_type": "markdown",
      "source": "## Survivors by Salutation"
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true,
        "_uuid": "93db0ec5826079d3c881d4ac3b26f25d89824ba7"
      },
      "cell_type": "code",
      "source": "#df_all.loc[train_index,:].groupby('Salutation').count()\n\n\ndf_survival_sal = df_survivalinfo.groupby(['Salutation','Survived'])['Name'].count()\ndf_survival_sal\n#df_all.loc[train_index,:].groupby('Salutation').count()['Name']\n\n#.index\n\n#pd.pivot_table(df_survivalinfo, values='Survived', index=['Salutation'],columns=['Survived'], aggfunc=np.sum)\n\n# values='D',\n#['Name']\n#df_survivalinfo.pivot(index='Salutation', columns='Name', values='Survived')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6bb49c60d50c31c70efd73d8881064a845bcf277"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8bdc27cdc34e3856b4970a224e9c3b007ca6affb"
      },
      "cell_type": "code",
      "source": "df_all[df_all['Salutation']=='Capt.']",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d626851b138b0c1f9df0156a1917c2c5a013809a"
      },
      "cell_type": "code",
      "source": "sns.set(style=\"whitegrid\")\n\n# Initialize the matplotlib figure\nf, ax = plt.subplots(figsize=(6, 15))\n\n# Load the example car crash dataset\n#crashes = sns.load_dataset(\"car_crashes\").sort_values(\"total\", ascending=False)\nsalutations = df_survivalinfo.groupby(['Salutation','Survived']).count()\n\n# Plot the total crashes\nsns.set_color_codes(\"pastel\")\nsns.barplot(x=\"Name\", y=, data=salutations,\n            label=\"Name\", color=\"b\")\n\n# Plot the crashes where alcohol was involved\nsns.set_color_codes(\"muted\")\nsns.barplot(x=\"alcohol\", y=\"abbrev\", data=salutations,\n            label=\"Alcohol-involved\", color=\"b\")\n\n# Add a legend and informative axis label\nax.legend(ncol=2, loc=\"lower right\", frameon=True)\nax.set(xlim=(0, 24), ylabel=\"\",\n       xlabel=\"Automobile collisions per billion miles\")\nsns.despine(left=True, bottom=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "9c3620a10c81100eb9d4a61dc15066cd75f076e6"
      },
      "cell_type": "markdown",
      "source": "## Gaussian distrbution for age and fare price zu survived = 1\n\nhttps://matplotlib.org/gallery/statistics/histogram_multihist.html#sphx-glr-gallery-statistics-histogram-multihist-py"
    },
    {
      "metadata": {
        "_uuid": "74001bbcd9ca2dbd12d0c38fb22ef98e1092e441"
      },
      "cell_type": "markdown",
      "source": "Am Ende müssen sich alle Eingerenzungen durch die Visualisierungen in den Prediction Model wiederfinden.\n(z.B.: min age, max age, mean age, in der Klasse xyz sorgt dafpr, dass du eher überlebts ...)"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "43447b2003a54ec1ba74e5cd4f731c25753cafa9",
        "scrolled": true
      },
      "cell_type": "code",
      "source": "fare_survived = df_survivalinfo[df_survivalinfo['Survived'] == 1]['Fare']\nfare_survived = df_survivalinfo['Fare']\n\nfare_survived.describe()['mean']\nfare_survived.describe()['std']\n\nfare_survived.describe()\nfare_survived.values\n\nage_survived = df_survivalinfo['Age']\n\nfare_survived",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "05b8e14d1a2a2caf5c57f85e9cdb5a3460e41eb2"
      },
      "cell_type": "code",
      "source": "inputfeature = fare_survived\n\nmu = inputfeature.describe()['mean']  # mean of distribution\nsigma = inputfeature.describe()['std']  # standard deviation of distribution\nx = mu + sigma * inputfeature.values\n\nnum_bins = 50\n\nfig, ax = plt.subplots(figsize=(12,7))\n\n# the histogram of the data\nn, bins, patches = ax.hist(inputfeature,num_bins, density=1)\n\n# add a 'best fit' line\ny = ((1 / (np.sqrt(2 * np.pi) * sigma)) *\n     np.exp(-0.5 * (1 / sigma * (bins - mu))**2))\nax.plot(bins, y, '--')\nax.set_xlabel('Fare Price')\nax.set_ylabel('Probability density')\nax.set_title(r'Histogram of IQ: $\\mu=100$, $\\sigma=15$')\n\n# Tweak spacing to prevent clipping of ylabel\n#fig.tight_layout()\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c5a1b8d958ab27ea624e88738bf5fc49fdacaf83"
      },
      "cell_type": "code",
      "source": "df_survivalinfo[df_survivalinfo['Survived'] == 1].describe()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7ff1a19ee1db5dca92abef23197fe9e1902f9a1a"
      },
      "cell_type": "markdown",
      "source": "## Survivor by Fare Price \n"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5ef8eb2eac0286d686455680528ecd2147416883"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "73cbec0ceb642f4a83f4faf69f334d8747a18456"
      },
      "cell_type": "code",
      "source": "# Pivot for age and fare\nptbl_survived = pd.DataFrame.pivot_table(df_survivalinfo, values=['Fare', 'Age', 'Survived'], index=['Sex', 'Pclass'],\n                     aggfunc={'Fare': np.mean,'Age': [min, max, np.mean], 'Survived': ['sum']})\nptbl_survived",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "83318e14299c74d1d70dfd0b6478f8012acfa398"
      },
      "cell_type": "markdown",
      "source": "### Ticketprice to Survival"
    },
    {
      "metadata": {
        "_uuid": "b37bb9b1ec78133e473c391ad51607f70aa98d22"
      },
      "cell_type": "markdown",
      "source": ""
    },
    {
      "metadata": {
        "_uuid": "b53cc48d5784ce58fdefbcf3ca25b4f6d43c1c24"
      },
      "cell_type": "markdown",
      "source": "### Scatter plot mit zwei features und dem dritten als Farbe der dots und größe der dots.\n"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ebebbdc221df1276fb1b92bb41c997136ff9e474"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "fb36454c556463bb2590d11136e0f033181fc448"
      },
      "cell_type": "markdown",
      "source": "## Overall Bivariate Relation"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "417b567643d6958c36b2b8aceeff0604979fa20a"
      },
      "cell_type": "code",
      "source": "sns.pairplot(df_survivalinfo, hue='Survived')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "52ac78df0732225443e096a0b2ab6b981969251a"
      },
      "cell_type": "markdown",
      "source": "An overview about the "
    },
    {
      "metadata": {
        "_uuid": "1e65defcddab1798b2eb0566144e5c88b082576e"
      },
      "cell_type": "markdown",
      "source": "# Model"
    },
    {
      "metadata": {
        "_uuid": "474a85c6a421e8fad34f8f25892178ce9af5f5d3"
      },
      "cell_type": "markdown",
      "source": "## Man müsste einen K-Nearest Neighbor Ansatz auf Basis der Ticketklasse, dem Geschlecht und vlt noch dem Alter aufbauen, da Ticketklasse und Geschlecht erheblichen Einfluss auf das Überleben hatten. Siehe oben die Skizzen\n"
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true,
        "_uuid": "db250cd8c5f9fa36b4964e85c481ecd7c6e8ab76"
      },
      "cell_type": "code",
      "source": "\ndf_all.loc[train_index,:]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true,
        "_uuid": "9046768b10ed202c4c2dd9af63ece2bbbed09eb2"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true,
        "_uuid": "6e2c828ac4ef0091bd9a0f440c3a1fa006c88af8"
      },
      "cell_type": "code",
      "source": "# One hot encoding for the categorical data\ndf_train_hot  = df_all.loc[train_index,:].copy()\ndf_train_hot = df_train_hot.drop(['Name','Ticket','Cabin'], axis=1)\ndf_train_hot = pd.get_dummies(df_train_hot, columns=['Sex','Embarked'])\n\n# train test split\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(df_train_hot, Survived, test_size = 0.18, random_state = 25)  ## 50  25 ## 0.25 25",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e6b843986b85e6bfc9d0423c509223cc4ba426e5",
        "scrolled": false
      },
      "cell_type": "code",
      "source": "# K-Nearest Neighbours\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\n\n\nX_train = X_train\ny_train = y_train\n\nKNNC = KNeighborsClassifier(n_neighbors=16)\nKNNC.fit(X_train, y_train)\n\ny_pred = KNNC.predict(X_test)\n\n# Summary of the predictions made by the classifier\nprint(classification_report(y_test, y_pred, target_names=['0','1']))\n\n\n# Accuracy score\n\n#print(y_test, y_pred)\n#print(y_test, y_pred)\n\n#print('accuracy is',accuracy_score(y_pred,y_test))\n\nprint (\"Models accuracy score: \", accuracy_score(y_test, y_pred))\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "89329844d828a63fb157f7ca8006b77e06bb408f"
      },
      "cell_type": "code",
      "source": "from yellowbrick.classifier import ClassificationReport\n\nclasses = [\"will not suvive\", \"will survive\"]\n\n##KNNCA = KNeighborsClassifier()\n\n# Instantiate the classification model and visualizer\nvisualizer = ClassificationReport(KNNC, classes=classes, support=True)\n\nvisualizer.fit(X_train, y_train)  # Fit the visualizer and the model\nvisualizer.score(X_test, y_test)  # Evaluate the model on the test data\ng = visualizer.poof()             # Draw/show/poof the data",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e0a0feae9cdebd2dce0d308944250056908a3879"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "aa26597c5a04f855b96b99ec274e71cd8d55dd80"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "be0ba9ed0353decedd90c3a805152989b2d3797f"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9dc73ad58d2cba281a9cbc9ffd5635819e025388"
      },
      "cell_type": "code",
      "source": "# confusion matrix\nprint(confusion_matrix(y_test, y_pred))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4643cd2a5f8c05701afc95693619a94f85e21cc0"
      },
      "cell_type": "code",
      "source": "from sklearn.model_selection import cross_val_score\n\n# creating odd list of K for KNN\nmyList = list(range(1,50))\n\n# subsetting just the odd ones\n#neighbors = list(filter(lambda x: x % 2 != 0, myList))\nneighbors = list(myList)\n\n\n# empty list that will hold cv scores\ncv_scores = []\n\n# perform 10-fold cross validation\nfor k in neighbors:\n    knn = KNeighborsClassifier(n_neighbors=k)\n    scores = cross_val_score(knn, X_train, y_train, cv=10, scoring='accuracy')\n    cv_scores.append(scores.mean())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c33b2f5179b6ea8fbbac624f5d7e6ed1fff0a3c4"
      },
      "cell_type": "code",
      "source": "# changing to misclassification error\nMSE = [1 - x for x in cv_scores]\n\n# determining best k\noptimal_k = neighbors[MSE.index(min(MSE))]\nprint (\"The optimal number of neighbors is %d\" % optimal_k)\n\n# plot misclassification error vs k\nplt.plot(neighbors, MSE)\nplt.xlabel('Number of Neighbors K')\nplt.ylabel('Misclassification Error')\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5d693688b99417c6a326a7d29cca5a8cfe166210",
        "scrolled": true
      },
      "cell_type": "code",
      "source": "neighbors\noptimal_k\nMSE",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "cf0a4c5fd530ab04f6f8f77599adc6e1295200dc"
      },
      "cell_type": "code",
      "source": "#MSE.index(min(MSE))\n\n#print(neighbors)\n\n#list(neighbors)\n#print(less_than_zero)\nprint(lambda x: x % 2 != 0)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d0ed1fbedb5e1b2ceaa37667c812eef73af37ea0"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "486121405ed4e0b844b420eae17ba3b771453c1b"
      },
      "cell_type": "code",
      "source": "# Fixing random state for reproducibility\nnp.random.seed(19680801)\n\n\n#N = 50\ny = df_survivalinfo.loc[train_index]['Fare'].values\nx = df_survivalinfo.loc[train_index]['Age'].values\nz = df_survivalinfo.loc[train_index]['Survived'].values\n#colors = np.random.rand(N)\n#area = (30 * np.random.rand(N))**2  # 0 to 15 point radii\n\n\n###for surv in z:\n###    if surv == 1:\n###        plt.plot(x, y, 'o', markerfacecolor='r',\n###            markeredgecolor='k', markersize=3)\n\n   \nplt.scatter(x, y) \n            #s=area, c=colors, alpha=0.5)\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2395eba41af481da1864de95c8c8db97573c5466"
      },
      "cell_type": "code",
      "source": "\n#N = 50\nx = df_all.loc[train_index]['Pclass'].values\ny = df_all.loc[train_index]['Fare'].values\n#colors = np.random.rand(N)\n#area = (30 * np.random.rand(N))**2  # 0 to 15 point radii\n\nplt.scatter(x, y) \n            #s=area, c=colors, alpha=0.5)\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true,
        "_uuid": "b5ed9f0b08f5a9729b8fd26c4d7715ddf0bce0a8"
      },
      "cell_type": "code",
      "source": "df_survivalinfo[['Pclass','Age']]\n\n# Only training data\ndf_all.loc[train_index][['Pclass','Age']]\n\ndf_all.loc[train_index][['Fare','Age']].values\ndf_all.loc[train_index]\n\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6ebc2a28a585b1744801d90a1aa824f63c707abe"
      },
      "cell_type": "code",
      "source": "### K - Means\n\nprint(__doc__)\n\n# Author: Phil Roth <mr.phil.roth@gmail.com>\n# License: BSD 3 clause\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom sklearn.cluster import KMeans\nfrom sklearn.datasets import make_blobs\n\nplt.figure(figsize=(12, 12))\n\nn_samples = 800\nrandom_state = 170\n#X, y = make_blobs(n_samples=n_samples, random_state=random_state)\n\nX = df_all.loc[train_index][['Age','Fare']].values\ny = Survived\n\n# Incorrect number of clusters\ny_pred = KMeans(n_clusters=4, random_state=random_state).fit_predict(X)\n\nplt.subplot(221)\nplt.scatter(X[:, 0], X[:, 1], c=y_pred)\nplt.title(\"Incorrect Number of Blobs\")\n\n# Anisotropicly distributed data\ntransformation = [[0.60834549, -0.63667341], [-0.40887718, 0.85253229]]\nX_aniso = np.dot(X, transformation)\ny_pred = KMeans(n_clusters=5, random_state=random_state).fit_predict(X_aniso)\n\nplt.subplot(222)\nplt.scatter(X_aniso[:, 0], X_aniso[:, 1], c=y_pred)\nplt.title(\"Anisotropicly Distributed Blobs\")\n\n# Different variance\nX_varied, y_varied = make_blobs(n_samples=n_samples,\n                                cluster_std=[1.0, 2.5, 0.5],\n                                random_state=random_state)\ny_pred = KMeans(n_clusters=3, random_state=random_state).fit_predict(X_varied)\n\nplt.subplot(223)\nplt.scatter(X_varied[:, 0], X_varied[:, 1], c=y_pred)\nplt.title(\"Unequal Variance\")\n\n# Unevenly sized blobs\nX_filtered = np.vstack((X[y == 0][:500], X[y == 1][:100], X[y == 2][:10]))\ny_pred = KMeans(n_clusters=3,\n                random_state=random_state).fit_predict(X_filtered)\n\nplt.subplot(224)\nplt.scatter(X_filtered[:, 0], X_filtered[:, 1], c=y_pred)\nplt.title(\"Unevenly Sized Blobs\")\n\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "fd66d3aadd529243d380c5e0694d9a6181cad1ef"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8792ed444b3550d02d0ecbf7e7bcfe210ef9729e",
        "scrolled": false
      },
      "cell_type": "code",
      "source": "### K nearest Neighbour\n\nprint(__doc__)\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import ListedColormap\nfrom sklearn import neighbors, datasets\n\nn_neighbors = 10\n\n# import some data to play with\niris = datasets.load_iris()\n\n# we only take the first two features. We could avoid this ugly\n# slicing by using a two-dim dataset\nX = df_all.loc[train_index][['Pclass','Age']].values\ny = Survived\n##X = iris.data[:, :2]\n##y = iris.target\n\nh = .02  # step size in the mesh\n\n# Create color maps\ncmap_light = ListedColormap(['#FFAAAA', '#AAFFAA', '#AAAAFF'])\ncmap_bold = ListedColormap(['#FF0000', '#00FF00', '#0000FF'])\n\nfor weights in ['uniform', 'distance']:\n    # we create an instance of Neighbours Classifier and fit the data.\n    clf = neighbors.KNeighborsClassifier(n_neighbors, weights=weights)\n    #clf = neighbors.RadiusNeighborsClassifier(n_neighbors, weights=weights)\n    \n    clf.fit(X, y)\n\n    # Plot the decision boundary. For that, we will assign a color to each\n    # point in the mesh [x_min, x_max]x[y_min, y_max].\n    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n                         np.arange(y_min, y_max, h))\n    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n\n    # Put the result into a color plot\n    Z = Z.reshape(xx.shape)\n    plt.figure()\n    plt.pcolormesh(xx, yy, Z, cmap=cmap_light)\n\n    # Plot also the training points\n    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=cmap_bold,\n                edgecolor='k', s=20)\n    plt.xlim(xx.min(), xx.max())\n    plt.ylim(yy.min(), yy.max())\n    plt.title(\"2-Class classification (k = %i, weights = '%s')\"\n              % (n_neighbors, weights))\n\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7ad237161ef3d88f7bc0598de2e22765ed408b69"
      },
      "cell_type": "code",
      "source": "centers = [[1, 1], [-1, -1], [1, -1]]\nX, labels_true = make_blobs(n_samples=750, centers=centers, cluster_std=0.4,\n                            random_state=0)\n\nX = StandardScaler().fit_transform(X)\nX",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a72122a2837af46c4d95e58b910a3a03a8301916"
      },
      "cell_type": "code",
      "source": "print(__doc__)\n\nimport numpy as np\n\nfrom sklearn.cluster import DBSCAN\nfrom sklearn import metrics\nfrom sklearn.datasets.samples_generator import make_blobs\nfrom sklearn.preprocessing import StandardScaler\n\n\n# #############################################################################\n# Generate sample data\n#centers = [[1, 1], [-1, -1], [1, -1]]\n#X, labels_true = make_blobs(n_samples=750, centers=centers, cluster_std=0.4,\n#                            random_state=0)\n\n#X = StandardScaler().fit_transform(X)\n\nX = df_all.loc[train_index][['Fare','Age']].values\n\n\n# #############################################################################\n# Compute DBSCAN\ndb = DBSCAN(eps=0.3, min_samples=10).fit(X)\ncore_samples_mask = np.zeros_like(db.labels_, dtype=bool)\ncore_samples_mask[db.core_sample_indices_] = True\nlabels = db.labels_\n\n# Number of clusters in labels, ignoring noise if present.\nn_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\nn_noise_ = list(labels).count(-1)\n\n##print('Estimated number of clusters: %d' % n_clusters_)\n##print('Estimated number of noise points: %d' % n_noise_)\n##print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(labels_true, labels))\n##print(\"Completeness: %0.3f\" % metrics.completeness_score(labels_true, labels))\n##print(\"V-measure: %0.3f\" % metrics.v_measure_score(labels_true, labels))\n##print(\"Adjusted Rand Index: %0.3f\"\n##      % metrics.adjusted_rand_score(labels_true, labels))\n##print(\"Adjusted Mutual Information: %0.3f\"\n##      % metrics.adjusted_mutual_info_score(labels_true, labels))\n##print(\"Silhouette Coefficient: %0.3f\"\n##      % metrics.silhouette_score(X, labels))\n\n# #############################################################################\n# Plot result\nimport matplotlib.pyplot as plt\n\n# Black removed and is used for noise instead.\nunique_labels = set(labels)\ncolors = [plt.cm.Spectral(each)\n          for each in np.linspace(0, 1, len(unique_labels))]\nfor k, col in zip(unique_labels, colors):\n    if k == -1:\n        # Black used for noise.\n        col = [0, 0, 0, 1]\n\n    class_member_mask = (labels == k)\n\n    xy = X[class_member_mask & core_samples_mask]\n    plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),\n             markeredgecolor='k', markersize=14)\n\n    xy = X[class_member_mask & ~core_samples_mask]\n    plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),\n             markeredgecolor='k', markersize=6)\n\nplt.title('Estimated number of clusters: %d' % n_clusters_)\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "1f4a6c625596da5c95e844b7e93c22b4e63187e0"
      },
      "cell_type": "markdown",
      "source": "## REAL DBSCAN Part"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1fb394aa9c54fa94923b77b0ef8733ca51deb868"
      },
      "cell_type": "code",
      "source": "## Data preparation part ###\ndf_survivalinfo_onehot  = df_survivalinfo.copy()\ndf_survivalinfo_onehot = pd.get_dummies(df_survivalinfo_onehot, columns=['Sex'], prefix = ['Sex'])\n\n\n### DBSCAN part ###\nprint(__doc__)\n\nimport numpy as np\n\nfrom sklearn.cluster import DBSCAN\nfrom sklearn import metrics\nfrom sklearn.datasets.samples_generator import make_blobs\nfrom sklearn.preprocessing import StandardScaler\n\n\n# #############################################################################\n# Generate sample data\n#centers = [[1, 1], [-1, -1], [1, -1]]\n#X, labels_true = make_blobs(n_samples=750, centers=centers, cluster_std=0.4,\n#                            random_state=0)\n\n#X = StandardScaler().fit_transform(X)\n\n#X = df_all.loc[train_index][['Fare','Age','Pclass', 'Family','SibSp','Parch']].values\n#X = df_all[['Fare','Age','Pclass', 'Family',]].values\n#X = df_survivalinfo[['Fare','Age','Pclass', 'Family','Survived']].values\n#X = df_survivalinfo[['Age','Survived','Fare','Pclass', 'Family']].values\n#####X = df_survivalinfo_onehot[['Fare','Age','Pclass', 'Family','Survived','Sex_female','Sex_male']].values\n#X = df_survivalinfo_onehot[['Pclass','Age','Fare','Sex_female','Sex_male','Family','Survived']].values\n#,'Sex_female','Sex_male','Family'\n\nX = df_survivalinfo_onehot[['Fare','Age']].values\n\n# #############################################################################\n# Compute DBSCAN  ### 10 25 ist gut\ndb = DBSCAN(eps=10, min_samples=5, algorithm='auto').fit(X)\ncore_samples_mask = np.zeros_like(db.labels_, dtype=bool)\ncore_samples_mask[db.core_sample_indices_] = True\nlabels = db.labels_\n\n# Number of clusters in labels, ignoring noise if present.\nn_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\nn_noise_ = list(labels).count(-1)\n\nprint('Estimated number of clusters: %d' % n_clusters_)\nprint('Estimated number of noise points: %d' % n_noise_)\n##print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(labels_true, labels))\n##print(\"Completeness: %0.3f\" % metrics.completeness_score(labels_true, labels))\n##print(\"V-measure: %0.3f\" % metrics.v_measure_score(labels_true, labels))\n##print(\"Adjusted Rand Index: %0.3f\"\n##      % metrics.adjusted_rand_score(labels_true, labels))\n##print(\"Adjusted Mutual Information: %0.3f\"\n##      % metrics.adjusted_mutual_info_score(labels_true, labels))\nprint(\"Silhouette Coefficient: %0.3f\"\n      % metrics.silhouette_score(X, labels))\n\n# #############################################################################\n# Plot result\nimport matplotlib.pyplot as plt\n\n# Figure size set\nplt.figure(figsize=(12,7))\n\n# Black removed and is used for noise instead.\nunique_labels = set(labels)\ncolors = [plt.cm.Spectral(each)\n          for each in np.linspace(0, 1, len(unique_labels))]\nfor k, col in zip(unique_labels, colors):\n    if k == -1:\n        # Black used for noise.\n        col = [0, 0, 0, 1]\n\n    class_member_mask = (labels == k)\n\n    xy = X[class_member_mask & core_samples_mask]\n    plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),\n             markeredgecolor='k', markersize=14)\n\n    xy = X[class_member_mask & ~core_samples_mask]\n    plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),\n             markeredgecolor='k', markersize=6)\n\nplt.title('Estimated number of clusters: %d' % n_clusters_)\n\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3c01476e518e191fb785fedcd2dfcdd8dd751c11"
      },
      "cell_type": "code",
      "source": "#pd.concat(,db.labels_)\n    \ndf_survivalinfo\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a5c9c982a60508bfdca1c0033cc5774043b487d0"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "47bebd8020edc890fa963a1a04fad40977515b47",
        "scrolled": false
      },
      "cell_type": "code",
      "source": "sns.pairplot(df_survivalinfo, hue='Survived')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "30c7b1a9ab8d1b8077a7fa6d1a2536701f8a7838"
      },
      "cell_type": "code",
      "source": "# seaborn's kdeplot, plots univariate or bivariate density estimates.\n#Size can be changed by tweeking the value used\nsns.FacetGrid(df_survivalinfo, hue=\"Survived\", height=5).map(sns.kdeplot, \"Pclass\").add_legend()\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6f94ca06ddafc1749d7e0358e68fe93851833b6f"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "1d017486d2fc544f5eed7e94893614684d7a3ec9"
      },
      "cell_type": "markdown",
      "source": "# Schrottsammler\n\n"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0fbebccc1bbd41674c9838694554ca13526bb0cb"
      },
      "cell_type": "code",
      "source": "## CABIN TRY #####\n\n\n\n\n# Creating a data frame for the Cabin values to split multiple values into seperate columns\ndf_cabin_expand = df_all.loc[:,'Cabin'].str.split(' ', expand=True)\n\n# While I transfered the cabin information to a string value to afterwards split the single list values.\n# Unfortunately, all nan fields were also converted. Therefore I cannot use the notna or notnull function to determin the ones with\n# filled information.\n# To fix that problem I will replace all NaN strings with a NaN object.\n\ndf_cabin_expand = df_cabin_expand.replace(['NaN','None'],np.nan)\n\n\ndf_all.loc[:,'Cabin'].str.split(' ', expand=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "798585c4512f76d6f32c4bc46a531254973023c3"
      },
      "cell_type": "markdown",
      "source": "### Violin Plotts with Seaborn"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c18acac6b847d0c50aeb3070ec59d102709d6bcf"
      },
      "cell_type": "code",
      "source": "\nfig, ax = plt.subplots(nrows=1, ncols=1, figsize=(14, 8) )\n\n# Font dictionary\nfont = {'color':  'black',\n        'weight': 'normal',\n        'size': 18,\n}\n\nsns.set(style=\"darkgrid\", font_scale=2)\n\nax = sns.violinplot(x='Pclass', y='Age', data=df_all )\n\nax.set_title('Age Distribution per Class', fontsize=25)\nax.set_xlabel('Class',fontdict=font, labelpad=20, fontsize=20)\nax.set_ylabel('Age', fontdict=font,labelpad=20, fontsize=20)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "72f82739dfdec44c122352454d052cc38e721040"
      },
      "cell_type": "markdown",
      "source": "### Age to Survived\n\nhttps://matplotlib.org/gallery/statistics/boxplot_vs_violin.html#sphx-glr-gallery-statistics-boxplot-vs-violin-py\n\nmin age <br>\nmax age  <br>\nmean age <br>\n\nper class\n\nboxplot je Pclass mit min age, max age, mean age"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4db9ca5276adf9673d36c3d5ff17b6ca65ea79e3"
      },
      "cell_type": "code",
      "source": "df_two_features = [df_all['Age'].values,df_all['Fare'].values ]\n\nfig, axes = plt.subplots(nrows=1, ncols=1, figsize=(12, 6))\n\n# plot violin plot\naxes.violinplot(df_two_features\n                   ,showmeans=False,\n                    showmedians=True)\naxes.set_title('Age and Fare Distribution')\n\n# adding horizontal grid lines\naxes.yaxis.grid(True)\naxes.set_xticks([y + 1 for y in range(len(df_two_features))])\naxes.set_xlabel('Two separate features')\naxes.set_ylabel('Observed values Age / Fare')\n\n# add x-tick labels\nplt.setp(axes, xticks=[y + 1 for y in range(len(df_two_features))],\n         xticklabels=['Age', 'Fare'], )\n\nplt.ylim(top=150)  # adjust the top leaving bottom unchanged\nplt.ylim(bottom=-20)  # adjust the bottom leaving top unchanged\n\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "7196cc7df9201d4ee942fa01cc951f90d4197e0f"
      },
      "cell_type": "markdown",
      "source": "### 4 Pie charts"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "962e2a499bc5d79d2a2b6d61962abb97294de612"
      },
      "cell_type": "code",
      "source": "# The dataset with survived information\ndf_survivalinfo = pd.concat([df_all, Survived], axis=1)\n\n# Survival distribution per Sex\ngp_survived_gender = df_survivalinfo.groupby(['Survived','Sex'])['Name'].count()[1]\n\n# Gender Survival\ngp_gender_survived = df_survivalinfo.groupby(['Sex','Survived']).count()['Name']\n\n# Survival distribution Y/N \ngp_survived_yn = df_survivalinfo.groupby(['Survived']).agg('count')['Name']\n\n\n\n# Labels and size based on survival group by (df_survivalinfo)\n#labels_suvinf = ['not suvived','survived']\nsizes_suvinf = [gp_survived_yn[y] for y in range(len(gp_survived_yn))]\nexplode_suvinf = (0, 0.1)  # only \"explode\" the 2nd slice (i.e. 'Hogs')\n\n# Labels and size based on gender group by (gp_sex_survived)\nlabels_sexinf = [gp_survived_gender.index[y] for y in range(len(gp_survived_gender.index))]\nsizes_sexinf = [gp_survived_gender[y] for y in range(len(gp_survived_gender))]\nexplode_sexinf = (0, 0.1)  # only \"explode\" the 2nd slice (i.e. 'Hogs')\n\n# Labels and size MALE Survivor Distribution\nlabels_maleinf = [gp_gender_survived['male'].index[y] for y in range(len(gp_gender_survived['male'].index))]\nsizes_maleinf = [gp_gender_survived['male'][y] for y in range(len(gp_gender_survived['male']))]\nexplode_maleinf = (0, 0.1)  # only \"explode\" the 2nd slice (i.e. 'Hogs')\n\n# Labels and size FEMALE Survivor Distribution\nlabels_femaleinf = [gp_gender_survived['female'].index[y] for y in range(len(gp_gender_survived['female'].index))]\nsizes_femaleinf = [gp_gender_survived['female'][y] for y in range(len(gp_gender_survived['female']))]\nexplode_femaleinf = (0, 0.1)  # only \"explode\" the 2nd slice (i.e. 'Hogs')\n\n\n# Font dictionary\nfont = {'color':  'black',\n        'weight': 'normal',\n        #'size': 15,\n        'fontsize':15\n}\n\ncmap = plt.get_cmap('tab20c')\nsurvivedcolor = cmap(np.array([5,1]))\n\n# Figure and axes1 and axes2 of the plot\ngridsize = (4,2)\nfig1 = plt.figure(figsize=(18,14))\nax1 = plt.subplot2grid(gridsize, (0,0))\nax2 = plt.subplot2grid(gridsize, (0,1))\nax3 = plt.subplot2grid(gridsize, (1,0))\nax4 = plt.subplot2grid(gridsize, (1,1))\n\n\n## ax1 \n# Define first pie for survival true falls\nax1.pie(sizes_suvinf, \n        explode=explode_suvinf,\n        #labels=labels_suvinf,\n        autopct='%1.1f%%',\n        shadow=True, startangle=90,\n        colors=survivedcolor,\n        labeldistance=1.15,\n        pctdistance=0.55\n       )\nax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\nax1.fontdict=font\nax1.legend(loc='upper left',fontsize='small',labels=('not survived', 'survived'))\nax1.set_title('Survivor Distribution', fontdict=font, fontsize=20)\n\n## ax2 \n# Define second pie for sex to survival\nax2.pie(sizes_sexinf, \n        explode=explode_sexinf,\n        #labels=labels_sexinf,\n        autopct='%1.1f%%',\n        shadow=True, startangle=90,\n        colors=outer_colors,\n        labeldistance=1.15,\n        pctdistance=0.55)\nax2.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\nax2.fontdict=font\nax2.legend(loc='upper right', fontsize='small', labels=labels_sexinf )\nax2.set_title('Gender Survivor Distribution', fontdict=font, fontsize=20)\n\nax3.pie(sizes_maleinf, \n        explode=explode_maleinf,\n        #labels=labels_sexinf,\n        autopct='%1.1f%%',\n        shadow=True, startangle=90,\n        colors=survivedcolor,\n        labeldistance=1.15,\n        pctdistance=0.55)\nax3.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\nax3.fontdict=font\nax3.legend(loc='lower left', fontsize='small', labels=['not survived','survived'] )\nax3.set_title('Male Survivor Distribution', fontdict=font, fontsize=20)\nax3.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n\n\nax4.pie(sizes_femaleinf, \n        explode=explode_femaleinf,\n        #labels=labels_sexinf,\n        autopct='%1.1f%%',\n        shadow=True, startangle=90,\n        colors=survivedcolor,\n        labeldistance=1.15,\n        pctdistance=0.55)\nax4.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\nax4.fontdict=font\nax4.legend(loc='lower right', fontsize='small', labels=['not survived','survived'] )\nax4.set_title('Female Survivor Distribution', fontdict=font, fontsize=20)\nax4.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n\n#plt.rcParams['font.size'] = 13.0\n#plt.rc_context\n\n\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "2e743f5206bd482b0970695f60d86cb22a8cdadc"
      },
      "cell_type": "markdown",
      "source": "## Ein weiterer Violin Plot"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8a5572d9c43d1770ec36a9670f313c61fc095ff6"
      },
      "cell_type": "code",
      "source": "df_two_features = [df_all['Age'].values,df_all['Fare'].values ]\n\nfig, axes = plt.subplots(nrows=1, ncols=1, figsize=(12, 6))\n\n# plot violin plot\naxes.violinplot(df_two_features\n                   ,showmeans=False,\n                    showmedians=True)\naxes.set_title('Age and Fare Distribution')\n\n# adding horizontal grid lines\naxes.yaxis.grid(True)\naxes.set_xticks([y + 1 for y in range(len(df_two_features))])\naxes.set_xlabel('Two separate features')\naxes.set_ylabel('Observed values Age / Fare')\n\n# add x-tick labels\nplt.setp(axes, xticks=[y + 1 for y in range(len(df_two_features))],\n         xticklabels=['Age', 'Fare'], )\n\nplt.ylim(top=150)  # adjust the top leaving bottom unchanged\nplt.ylim(bottom=-20)  # adjust the bottom leaving top unchanged\n\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "860831198456eda0d5093e640fbadbf7a9ac798d"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e00bcc1d69d6af88558ca21e74fa2a75555c012d"
      },
      "cell_type": "code",
      "source": "#df_fristclass_ages\n#test= pd.DataFrame(df_all[df_all.loc[:,'Pclass'] == 1]['Age'].copy())\n#test\n\nfirstclass = pd.DataFrame(df_all[df_all.loc[:,'Pclass'] == 1]['Age'].copy())\nsecondclass = pd.DataFrame(df_all[df_all.loc[:,'Pclass'] == 2]['Age'].copy())\nthirdclass = pd.DataFrame(df_all[df_all.loc[:,'Pclass'] == 3]['Age'].copy())\n\ndf_firstclass_ages.rename\n\n# violin plot\nframe = [df_firstclass_ages\n    ,df_secondclass_ages\n    ,df_thirdclass_ages]\n\nresults = pd.concat(frame,axis =1)\n\nresults.columns = ['Firstclass_Age','Secondclass_Age','Thirdclass_Age']",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "92e29617ac304ea54c2dc38ad1d8988593ce953a"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3bf2fc7ca4b53acee739f561f818a7cbfa404fdc"
      },
      "cell_type": "code",
      "source": "# violin plot\nframe = [df_firstclass_ages\n    ,df_secondclass_ages\n    ,df_thirdclass_ages]\n\nresults = pd.concat(frame,axis =1)\nresults.rename(index=str, columns={\"Age\": \"Age Firstclass\"})",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6ffe38af6c083734c4c1bd6b402aeb996d964c1d"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3080a33c011a8c49a1d13c8b39cad4b59e09385b"
      },
      "cell_type": "code",
      "source": "# Concat Survived and training set \nfig = plt.figure(figsize=(12,10))\n#gs = fig.add_gridspec(2, 2)\n#ax1 = fig.add_subplot(gs[0, 0])\nax = fig.add_subplot()\n\n\n\ndf_all_survived = pd.concat([df_all.loc[train_index,:],Survived], axis=1)\ndf_all_survived \n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "867c7c878e4fa3dfeb881ed98e7ceee9011e1046"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "14ca70d05d914053d82607d68dd2d87d61e0e509"
      },
      "cell_type": "code",
      "source": "n_groups = 10\n\n# Mans value count per type\nmeans_men = df_all.groupby(['Sex']).count().loc['male',:].values\n#std_men = (2, 3, 4, 1, 2)\n\n# Womens value count per type\nmeans_women = df_all.groupby(['Sex']).count().loc['female',:].values\n#std_women = (3, 5, 2, 3, 3)\n\n\n\nfig, ax = plt.subplots(figsize=(10,6))\n\n\nindex = np.arange(n_groups)\nbar_width = 0.35\n\nopacity = 0.4\nerror_config = {'ecolor': '0.3'}\n\nrects1 = ax.bar(index, means_men, bar_width,\n                alpha=opacity, color='b',\n                error_kw=error_config,\n                label='Men')\n\nrects2 = ax.bar(index + bar_width, means_women, bar_width,\n                alpha=opacity, color='g',\n                error_kw=error_config,\n                label='Women')\n\nax.set_xlabel('Group')\nax.set_ylabel('Count')\nax.set_title('Scores by group and gender')\nax.set_xticks(index + bar_width / 2)\nax.set_xticklabels(('Pclass','Name','Age','SibSp','Parch','Ticket','Fare','Cabin','Embarked','Family'))\nax.legend()\n\nfig.tight_layout()\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c1d801d2d55f02ac1954c51d83c1ea66fa7431ea"
      },
      "cell_type": "code",
      "source": "df_all.groupby(['Sex','Pclass']).count().index\ndf_all.groupby(['Sex','Pclass']).count()['female']\n#index.levels[1]\n#df_all.groupby(['Sex','Pclass']).count().index.levels[0]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e9d3af18a70158b7b685a5a1f19e06c3be1c9d6f"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4082f42170545cae9de74c1eb4baec310376d724"
      },
      "cell_type": "code",
      "source": "#df_all.groupby(['Sex']).count().Name\n#df_all.groupby(['Sex','Pclass']).count().Name\n\ndf_all.groupby(['Sex','Pclass']).count().loc['female']\n\n#df_all.groupby(['Sex','Pclass']).count().loc\n\n#.loc['male']\n\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true,
        "_uuid": "1a4026b5b103ac86494bd53139ebdaa744a8733d"
      },
      "cell_type": "code",
      "source": "#df_all.pivot(columns='Sex', values=['Fare','Pclass'])\ndf_all.pivot(columns='Pclass', values=['Fare']) # very good one\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9eb8690e1203dc075545689e9e5ceb82a644c39b"
      },
      "cell_type": "code",
      "source": "#df_all['Sex'].values\n#Survived.values\ndf_all.groupby(['Sex']).count().Name.male",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true,
        "_uuid": "6d26b901bb57cc0b0c77d7eeddbf408617f19823"
      },
      "cell_type": "code",
      "source": "\n#fig = plt.figure() # figure\n#fig.suptitle('Gender Seperation on 'Titanic')\n\nfig, ax = plt.subplots(1,1)\n#my_plotter(ax,df_train['Sex'].values, Survived.values, {: 'x'})\nmy_bar(ax, df_train['Sex'].values, Survived.values, {'facecolor':'r'})\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1bc7af7c656077ed2c7f5c01686ee30f7d372867"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "12e595cafc7d3829134e7727eece81d97e548a5a"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a82eea1792584a362cf5b5c80a8fbbe20b75ac40"
      },
      "cell_type": "code",
      "source": "#df_all[['Sex','Age','SibSp','Parch','Embarked','Family']].hist(Survived)\npd.concat([df_train, Survived], axis=1).hist()\n#.hist()\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d3fb19147bd986498cf2db175f1d4867c4c5f8e7"
      },
      "cell_type": "code",
      "source": "df_all.groupby(['Sex']).count().loc['female',:].values",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5ae17d538f101b22d522f13ede2e862c9a68f6f9"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "73e387e5e03e137fd09de21dbf8d8794306247f7"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "cff1581a5fbeff93be2f95b6751421c2948b66c0"
      },
      "cell_type": "code",
      "source": "df_all.pivot(\"Pclass\", \"Age\", \"Sex\")\n\n#passengers = sns.load_dataset(\"flights\")\n#flights = df_all.pivot(\"Pclass\", \"Age\", \"Sex\")\n#ax = sns.heatmap(flights)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1dfcf8d78947a75d74c4f2fae6eae81da4ffd4d6"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0058369b5d82b90e15f123d2a2c62edc8b6df6d7"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0d4a9ad903b920a020c98dc4de010131d3de1f3e"
      },
      "cell_type": "code",
      "source": "df_all[(df_all['Ticket'].str.contains('PC', regex=False) == True)]\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "125e377f896f3f304920b6850caa2ec261cd6a73"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}